{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyP3hBFhOVKm7Q9oMEApi5AQ"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/gdrive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"D3BbnueDcw0v","executionInfo":{"status":"ok","timestamp":1706636364563,"user_tz":-360,"elapsed":30681,"user":{"displayName":"Rashed Hassan Siam","userId":"08405552312238656928"}},"outputId":"c808533a-04f3-4cdb-f1aa-ddfc608aa2a0"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /gdrive\n"]}]},{"cell_type":"code","execution_count":3,"metadata":{"id":"f_wyJppVcKi8","executionInfo":{"status":"ok","timestamp":1706636689119,"user_tz":-360,"elapsed":1427,"user":{"displayName":"Rashed Hassan Siam","userId":"08405552312238656928"}}},"outputs":[],"source":["import dlib , cv2\n","\n","# This function is computationally expensive:\n","def face_detection_1(img):\n","    \"\"\"Extract the faces from the image:\n","        returns : list of faces , image with bounding box on faces\n","        list of faces : are ready for input to the learning model just adjust the INPUT_SHAPE\n","    \"\"\"\n","    detector = dlib.cnn_face_detection_model_v1('/gdrive/MyDrive/Colab Notebooks/face_detection-main/important files/mmod_human_face_detector.dat')\n","#     detector = dlib.get_frontal_face_detector()\n","    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    faces = detector(gray_img)\n","    cropped_faces = []\n","    take = 7  # increase the size of the bounding box\n","    for face in faces:\n","        cropped_faces.append(img[ face.rect.top()-take :face.rect.bottom()+take, face.rect.left()-take:face.rect.right()+take , :].copy())\n","    for face in faces:\n","        cv2.rectangle(img,(face.rect.left()-5, face.rect.top()-5), (face.rect.right()+5, face.rect.bottom()+5) ,(0,255,0), 5)\n","    return cropped_faces , img\n","\n","\n","# This function is computationally less expensive and faster:\n","def face_detection_2(img):\n","    detector = dlib.get_frontal_face_detector()\n","    gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n","    faces = detector(gray_img )\n","    cropped_faces = []\n","    take = 7  # increase the size of the bounding box\n","    for face in faces:\n","        cropped_faces.append(img[ face.top()-take :face.bottom()+take, face.left()-take:face.right()+take , :].copy())\n","    for face in faces:\n","        cv2.rectangle(img,(face.left()-5, face.top()-5), (face.right()+5, face.bottom()+5) ,(0,255,0), 5)\n","    return cropped_faces , img\n","\n","\n","# def face_detection_mtcnn(img_path):\n","#     img = cv2.cvtColor(cv2.imread(img_path), cv2.COLOR_BGR2RGB)\n","#     detector = MTCNN()\n","#     detections = detector.detect_faces(img)\n","#     img_with_dets = img.copy()\n","#     min_conf = 0.9\n","#     for det in detections:\n","#         if det['confidence'] >= min_conf:\n","#             x, y, width, height = det['box']\n","#             keypoints = det['keypoints']\n","#             cv2.rectangle(img_with_dets, (x,y), (x+width,y+height), (0,155,255), 3)\n","#             # cv2.circle(img_with_dets, (keypoints['left_eye']), 2, (0,155,255), 2)\n","#             # cv2.circle(img_with_dets, (keypoints['right_eye']), 2, (0,155,255), 2)\n","#             # cv2.circle(img_with_dets, (keypoints['nose']), 2, (0,155,255), 2)\n","#             # cv2.circle(img_with_dets, (keypoints['mouth_left']), 2, (0,155,255), 2)\n","#             # cv2.circle(img_with_dets, (keypoints['mouth_right']), 2, (0,155,255), 2)\n","#     plt.figure(figsize = (50,50))\n","#     plt.imshow(img_with_dets)\n","#     plt.axis('off')"]}]}